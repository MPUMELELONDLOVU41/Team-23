{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "regression_challenge_4_student_version-1702.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MPUMELELONDLOVU41/Team-23/blob/master/regression_challenge_4_student_version_MPUMELELO_NDLOVU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DizI5Sugv7y7",
        "colab_type": "text"
      },
      "source": [
        "# Decision Tree Regression on the World Population\n",
        "Â© Explore Data Science Academy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZWAy-dvv7y-",
        "colab_type": "text"
      },
      "source": [
        "In this test we'll train a simple decision tree model using the world population data from the Analyse Practical Exam. \n",
        "\n",
        "<img src=\"https://github.com/Explore-AI/Pictures/blob/master/population.png?raw=true\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzSafG9m3FJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXnJbp-4v7zA",
        "colab_type": "text"
      },
      "source": [
        "## Honour Code\n",
        "\n",
        "I ***MPUMELELO***, ***NDLOVU*** confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
        "\n",
        "Non-compliance with the honour code constitutes a material breach of contract.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9Uo9bN8v7zB",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S47MGNruv7zC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qkm4KCAJv7zH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "population_df = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/AnalyseProject/world_population.csv', index_col='Country Code')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRI6mB76v7zL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "4ffd1e3f-c17c-4501-ba09-173ec7856010"
      },
      "source": [
        "population_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1960</th>\n",
              "      <th>1961</th>\n",
              "      <th>1962</th>\n",
              "      <th>1963</th>\n",
              "      <th>1964</th>\n",
              "      <th>1965</th>\n",
              "      <th>1966</th>\n",
              "      <th>1967</th>\n",
              "      <th>1968</th>\n",
              "      <th>1969</th>\n",
              "      <th>1970</th>\n",
              "      <th>1971</th>\n",
              "      <th>1972</th>\n",
              "      <th>1973</th>\n",
              "      <th>1974</th>\n",
              "      <th>1975</th>\n",
              "      <th>1976</th>\n",
              "      <th>1977</th>\n",
              "      <th>1978</th>\n",
              "      <th>1979</th>\n",
              "      <th>1980</th>\n",
              "      <th>1981</th>\n",
              "      <th>1982</th>\n",
              "      <th>1983</th>\n",
              "      <th>1984</th>\n",
              "      <th>1985</th>\n",
              "      <th>1986</th>\n",
              "      <th>1987</th>\n",
              "      <th>1988</th>\n",
              "      <th>1989</th>\n",
              "      <th>1990</th>\n",
              "      <th>1991</th>\n",
              "      <th>1992</th>\n",
              "      <th>1993</th>\n",
              "      <th>1994</th>\n",
              "      <th>1995</th>\n",
              "      <th>1996</th>\n",
              "      <th>1997</th>\n",
              "      <th>1998</th>\n",
              "      <th>1999</th>\n",
              "      <th>2000</th>\n",
              "      <th>2001</th>\n",
              "      <th>2002</th>\n",
              "      <th>2003</th>\n",
              "      <th>2004</th>\n",
              "      <th>2005</th>\n",
              "      <th>2006</th>\n",
              "      <th>2007</th>\n",
              "      <th>2008</th>\n",
              "      <th>2009</th>\n",
              "      <th>2010</th>\n",
              "      <th>2011</th>\n",
              "      <th>2012</th>\n",
              "      <th>2013</th>\n",
              "      <th>2014</th>\n",
              "      <th>2015</th>\n",
              "      <th>2016</th>\n",
              "      <th>2017</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Country Code</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ABW</th>\n",
              "      <td>54211.0</td>\n",
              "      <td>55438.0</td>\n",
              "      <td>56225.0</td>\n",
              "      <td>56695.0</td>\n",
              "      <td>57032.0</td>\n",
              "      <td>57360.0</td>\n",
              "      <td>57715.0</td>\n",
              "      <td>58055.0</td>\n",
              "      <td>58386.0</td>\n",
              "      <td>58726.0</td>\n",
              "      <td>59063.0</td>\n",
              "      <td>59440.0</td>\n",
              "      <td>59840.0</td>\n",
              "      <td>60243.0</td>\n",
              "      <td>60528.0</td>\n",
              "      <td>60657.0</td>\n",
              "      <td>60586.0</td>\n",
              "      <td>60366.0</td>\n",
              "      <td>60103.0</td>\n",
              "      <td>59980.0</td>\n",
              "      <td>60096.0</td>\n",
              "      <td>60567.0</td>\n",
              "      <td>61345.0</td>\n",
              "      <td>62201.0</td>\n",
              "      <td>62836.0</td>\n",
              "      <td>63026.0</td>\n",
              "      <td>62644.0</td>\n",
              "      <td>61833.0</td>\n",
              "      <td>61079.0</td>\n",
              "      <td>61032.0</td>\n",
              "      <td>62149.0</td>\n",
              "      <td>64622.0</td>\n",
              "      <td>68235.0</td>\n",
              "      <td>72504.0</td>\n",
              "      <td>76700.0</td>\n",
              "      <td>80324.0</td>\n",
              "      <td>83200.0</td>\n",
              "      <td>85451.0</td>\n",
              "      <td>87277.0</td>\n",
              "      <td>89005.0</td>\n",
              "      <td>90853.0</td>\n",
              "      <td>92898.0</td>\n",
              "      <td>94992.0</td>\n",
              "      <td>97017.0</td>\n",
              "      <td>98737.0</td>\n",
              "      <td>100031.0</td>\n",
              "      <td>100832.0</td>\n",
              "      <td>101220.0</td>\n",
              "      <td>101353.0</td>\n",
              "      <td>101453.0</td>\n",
              "      <td>101669.0</td>\n",
              "      <td>102053.0</td>\n",
              "      <td>102577.0</td>\n",
              "      <td>103187.0</td>\n",
              "      <td>103795.0</td>\n",
              "      <td>104341.0</td>\n",
              "      <td>104822.0</td>\n",
              "      <td>105264.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AFG</th>\n",
              "      <td>8996351.0</td>\n",
              "      <td>9166764.0</td>\n",
              "      <td>9345868.0</td>\n",
              "      <td>9533954.0</td>\n",
              "      <td>9731361.0</td>\n",
              "      <td>9938414.0</td>\n",
              "      <td>10152331.0</td>\n",
              "      <td>10372630.0</td>\n",
              "      <td>10604346.0</td>\n",
              "      <td>10854428.0</td>\n",
              "      <td>11126123.0</td>\n",
              "      <td>11417825.0</td>\n",
              "      <td>11721940.0</td>\n",
              "      <td>12027822.0</td>\n",
              "      <td>12321541.0</td>\n",
              "      <td>12590286.0</td>\n",
              "      <td>12840299.0</td>\n",
              "      <td>13067538.0</td>\n",
              "      <td>13237734.0</td>\n",
              "      <td>13306695.0</td>\n",
              "      <td>13248370.0</td>\n",
              "      <td>13053954.0</td>\n",
              "      <td>12749645.0</td>\n",
              "      <td>12389269.0</td>\n",
              "      <td>12047115.0</td>\n",
              "      <td>11783050.0</td>\n",
              "      <td>11601041.0</td>\n",
              "      <td>11502761.0</td>\n",
              "      <td>11540888.0</td>\n",
              "      <td>11777609.0</td>\n",
              "      <td>12249114.0</td>\n",
              "      <td>12993657.0</td>\n",
              "      <td>13981231.0</td>\n",
              "      <td>15095099.0</td>\n",
              "      <td>16172719.0</td>\n",
              "      <td>17099541.0</td>\n",
              "      <td>17822884.0</td>\n",
              "      <td>18381605.0</td>\n",
              "      <td>18863999.0</td>\n",
              "      <td>19403676.0</td>\n",
              "      <td>20093756.0</td>\n",
              "      <td>20966463.0</td>\n",
              "      <td>21979923.0</td>\n",
              "      <td>23064851.0</td>\n",
              "      <td>24118979.0</td>\n",
              "      <td>25070798.0</td>\n",
              "      <td>25893450.0</td>\n",
              "      <td>26616792.0</td>\n",
              "      <td>27294031.0</td>\n",
              "      <td>28004331.0</td>\n",
              "      <td>28803167.0</td>\n",
              "      <td>29708599.0</td>\n",
              "      <td>30696958.0</td>\n",
              "      <td>31731688.0</td>\n",
              "      <td>32758020.0</td>\n",
              "      <td>33736494.0</td>\n",
              "      <td>34656032.0</td>\n",
              "      <td>35530081.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGO</th>\n",
              "      <td>5643182.0</td>\n",
              "      <td>5753024.0</td>\n",
              "      <td>5866061.0</td>\n",
              "      <td>5980417.0</td>\n",
              "      <td>6093321.0</td>\n",
              "      <td>6203299.0</td>\n",
              "      <td>6309770.0</td>\n",
              "      <td>6414995.0</td>\n",
              "      <td>6523791.0</td>\n",
              "      <td>6642632.0</td>\n",
              "      <td>6776381.0</td>\n",
              "      <td>6927269.0</td>\n",
              "      <td>7094834.0</td>\n",
              "      <td>7277960.0</td>\n",
              "      <td>7474338.0</td>\n",
              "      <td>7682479.0</td>\n",
              "      <td>7900997.0</td>\n",
              "      <td>8130988.0</td>\n",
              "      <td>8376147.0</td>\n",
              "      <td>8641521.0</td>\n",
              "      <td>8929900.0</td>\n",
              "      <td>9244507.0</td>\n",
              "      <td>9582156.0</td>\n",
              "      <td>9931562.0</td>\n",
              "      <td>10277321.0</td>\n",
              "      <td>10609042.0</td>\n",
              "      <td>10921037.0</td>\n",
              "      <td>11218268.0</td>\n",
              "      <td>11513968.0</td>\n",
              "      <td>11827237.0</td>\n",
              "      <td>12171441.0</td>\n",
              "      <td>12553446.0</td>\n",
              "      <td>12968345.0</td>\n",
              "      <td>13403734.0</td>\n",
              "      <td>13841301.0</td>\n",
              "      <td>14268994.0</td>\n",
              "      <td>14682284.0</td>\n",
              "      <td>15088981.0</td>\n",
              "      <td>15504318.0</td>\n",
              "      <td>15949766.0</td>\n",
              "      <td>16440924.0</td>\n",
              "      <td>16983266.0</td>\n",
              "      <td>17572649.0</td>\n",
              "      <td>18203369.0</td>\n",
              "      <td>18865716.0</td>\n",
              "      <td>19552542.0</td>\n",
              "      <td>20262399.0</td>\n",
              "      <td>20997687.0</td>\n",
              "      <td>21759420.0</td>\n",
              "      <td>22549547.0</td>\n",
              "      <td>23369131.0</td>\n",
              "      <td>24218565.0</td>\n",
              "      <td>25096150.0</td>\n",
              "      <td>25998340.0</td>\n",
              "      <td>26920466.0</td>\n",
              "      <td>27859305.0</td>\n",
              "      <td>28813463.0</td>\n",
              "      <td>29784193.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ALB</th>\n",
              "      <td>1608800.0</td>\n",
              "      <td>1659800.0</td>\n",
              "      <td>1711319.0</td>\n",
              "      <td>1762621.0</td>\n",
              "      <td>1814135.0</td>\n",
              "      <td>1864791.0</td>\n",
              "      <td>1914573.0</td>\n",
              "      <td>1965598.0</td>\n",
              "      <td>2022272.0</td>\n",
              "      <td>2081695.0</td>\n",
              "      <td>2135479.0</td>\n",
              "      <td>2187853.0</td>\n",
              "      <td>2243126.0</td>\n",
              "      <td>2296752.0</td>\n",
              "      <td>2350124.0</td>\n",
              "      <td>2404831.0</td>\n",
              "      <td>2458526.0</td>\n",
              "      <td>2513546.0</td>\n",
              "      <td>2566266.0</td>\n",
              "      <td>2617832.0</td>\n",
              "      <td>2671997.0</td>\n",
              "      <td>2726056.0</td>\n",
              "      <td>2784278.0</td>\n",
              "      <td>2843960.0</td>\n",
              "      <td>2904429.0</td>\n",
              "      <td>2964762.0</td>\n",
              "      <td>3022635.0</td>\n",
              "      <td>3083605.0</td>\n",
              "      <td>3142336.0</td>\n",
              "      <td>3227943.0</td>\n",
              "      <td>3286542.0</td>\n",
              "      <td>3266790.0</td>\n",
              "      <td>3247039.0</td>\n",
              "      <td>3227287.0</td>\n",
              "      <td>3207536.0</td>\n",
              "      <td>3187784.0</td>\n",
              "      <td>3168033.0</td>\n",
              "      <td>3148281.0</td>\n",
              "      <td>3128530.0</td>\n",
              "      <td>3108778.0</td>\n",
              "      <td>3089027.0</td>\n",
              "      <td>3060173.0</td>\n",
              "      <td>3051010.0</td>\n",
              "      <td>3039616.0</td>\n",
              "      <td>3026939.0</td>\n",
              "      <td>3011487.0</td>\n",
              "      <td>2992547.0</td>\n",
              "      <td>2970017.0</td>\n",
              "      <td>2947314.0</td>\n",
              "      <td>2927519.0</td>\n",
              "      <td>2913021.0</td>\n",
              "      <td>2905195.0</td>\n",
              "      <td>2900401.0</td>\n",
              "      <td>2895092.0</td>\n",
              "      <td>2889104.0</td>\n",
              "      <td>2880703.0</td>\n",
              "      <td>2876101.0</td>\n",
              "      <td>2873457.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AND</th>\n",
              "      <td>13411.0</td>\n",
              "      <td>14375.0</td>\n",
              "      <td>15370.0</td>\n",
              "      <td>16412.0</td>\n",
              "      <td>17469.0</td>\n",
              "      <td>18549.0</td>\n",
              "      <td>19647.0</td>\n",
              "      <td>20758.0</td>\n",
              "      <td>21890.0</td>\n",
              "      <td>23058.0</td>\n",
              "      <td>24276.0</td>\n",
              "      <td>25559.0</td>\n",
              "      <td>26892.0</td>\n",
              "      <td>28232.0</td>\n",
              "      <td>29520.0</td>\n",
              "      <td>30705.0</td>\n",
              "      <td>31777.0</td>\n",
              "      <td>32771.0</td>\n",
              "      <td>33737.0</td>\n",
              "      <td>34818.0</td>\n",
              "      <td>36067.0</td>\n",
              "      <td>37500.0</td>\n",
              "      <td>39114.0</td>\n",
              "      <td>40867.0</td>\n",
              "      <td>42706.0</td>\n",
              "      <td>44600.0</td>\n",
              "      <td>46517.0</td>\n",
              "      <td>48455.0</td>\n",
              "      <td>50434.0</td>\n",
              "      <td>52448.0</td>\n",
              "      <td>54509.0</td>\n",
              "      <td>56671.0</td>\n",
              "      <td>58888.0</td>\n",
              "      <td>60971.0</td>\n",
              "      <td>62677.0</td>\n",
              "      <td>63850.0</td>\n",
              "      <td>64360.0</td>\n",
              "      <td>64327.0</td>\n",
              "      <td>64142.0</td>\n",
              "      <td>64370.0</td>\n",
              "      <td>65390.0</td>\n",
              "      <td>67341.0</td>\n",
              "      <td>70049.0</td>\n",
              "      <td>73182.0</td>\n",
              "      <td>76244.0</td>\n",
              "      <td>78867.0</td>\n",
              "      <td>80991.0</td>\n",
              "      <td>82683.0</td>\n",
              "      <td>83861.0</td>\n",
              "      <td>84462.0</td>\n",
              "      <td>84449.0</td>\n",
              "      <td>83751.0</td>\n",
              "      <td>82431.0</td>\n",
              "      <td>80788.0</td>\n",
              "      <td>79223.0</td>\n",
              "      <td>78014.0</td>\n",
              "      <td>77281.0</td>\n",
              "      <td>76965.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   1960       1961  ...        2016        2017\n",
              "Country Code                        ...                        \n",
              "ABW             54211.0    55438.0  ...    104822.0    105264.0\n",
              "AFG           8996351.0  9166764.0  ...  34656032.0  35530081.0\n",
              "AGO           5643182.0  5753024.0  ...  28813463.0  29784193.0\n",
              "ALB           1608800.0  1659800.0  ...   2876101.0   2873457.0\n",
              "AND             13411.0    14375.0  ...     77281.0     76965.0\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5uEHLCtv7zO",
        "colab_type": "text"
      },
      "source": [
        "### Question 1: Population Growth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGChWOn-v7zP",
        "colab_type": "text"
      },
      "source": [
        "The world population data spans from 1960 to 2017. We'd like to build a predictive model that can give us the best guess at what the population growth rate in a given year might be. We will calculate the population growth rate as follows:-\n",
        "\n",
        "$$\n",
        "Growth\\_rate = \\frac{current\\_year\\_population - previous\\_year\\_population}{previous\\_year\\_population}\n",
        "$$\n",
        "\n",
        "As such, we can only calculate the growth rate for the year 1961 onwards.\n",
        "\n",
        "Write a function that takes the `population_df` and a `country_code` as input and computes the population growth rate for a given country starting from the year 1961. This function must return a return a 2-d numpy array that contains the year and corresponding growth rate for the country.\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should take a `population_df` and `country_code` string as input and return a numpy `array` as output.\n",
        "* The array should only have two columns containing the year and the population growth rate, in other words, it should have a shape `(?, 2)` where `?` is the length of the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkTPQw3rv7zQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### START FUNCTION\n",
        "def get_population_growth_rate_by_country_year(df,country_code):\n",
        "    # your code here\n",
        "    GROWTH_POP =[]\n",
        "    a = population_df.columns\n",
        "    for i in a:\n",
        "        if i != a[-1]:\n",
        "            j =(population_df.at[country_code,str(int(i)+1)] - population_df.at[country_code,i])/population_df.at[country_code,i]\n",
        "            k = (int(i)+1)\n",
        "            GROWTH_POP.append([round(float(k),5),round(float(j),5)])\n",
        "\n",
        "    return np.array(GROWTH_POP)\n",
        "\n",
        "### END FUNCTION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1YcQLQMv7zT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "25d91e60-eb87-456b-e4ca-930393555a58"
      },
      "source": [
        "get_population_growth_rate_by_country_year(population_df,'ABW')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.961e+03,  2.263e-02],\n",
              "       [ 1.962e+03,  1.420e-02],\n",
              "       [ 1.963e+03,  8.360e-03],\n",
              "       [ 1.964e+03,  5.940e-03],\n",
              "       [ 1.965e+03,  5.750e-03],\n",
              "       [ 1.966e+03,  6.190e-03],\n",
              "       [ 1.967e+03,  5.890e-03],\n",
              "       [ 1.968e+03,  5.700e-03],\n",
              "       [ 1.969e+03,  5.820e-03],\n",
              "       [ 1.970e+03,  5.740e-03],\n",
              "       [ 1.971e+03,  6.380e-03],\n",
              "       [ 1.972e+03,  6.730e-03],\n",
              "       [ 1.973e+03,  6.730e-03],\n",
              "       [ 1.974e+03,  4.730e-03],\n",
              "       [ 1.975e+03,  2.130e-03],\n",
              "       [ 1.976e+03, -1.170e-03],\n",
              "       [ 1.977e+03, -3.630e-03],\n",
              "       [ 1.978e+03, -4.360e-03],\n",
              "       [ 1.979e+03, -2.050e-03],\n",
              "       [ 1.980e+03,  1.930e-03],\n",
              "       [ 1.981e+03,  7.840e-03],\n",
              "       [ 1.982e+03,  1.285e-02],\n",
              "       [ 1.983e+03,  1.395e-02],\n",
              "       [ 1.984e+03,  1.021e-02],\n",
              "       [ 1.985e+03,  3.020e-03],\n",
              "       [ 1.986e+03, -6.060e-03],\n",
              "       [ 1.987e+03, -1.295e-02],\n",
              "       [ 1.988e+03, -1.219e-02],\n",
              "       [ 1.989e+03, -7.700e-04],\n",
              "       [ 1.990e+03,  1.830e-02],\n",
              "       [ 1.991e+03,  3.979e-02],\n",
              "       [ 1.992e+03,  5.591e-02],\n",
              "       [ 1.993e+03,  6.256e-02],\n",
              "       [ 1.994e+03,  5.787e-02],\n",
              "       [ 1.995e+03,  4.725e-02],\n",
              "       [ 1.996e+03,  3.580e-02],\n",
              "       [ 1.997e+03,  2.706e-02],\n",
              "       [ 1.998e+03,  2.137e-02],\n",
              "       [ 1.999e+03,  1.980e-02],\n",
              "       [ 2.000e+03,  2.076e-02],\n",
              "       [ 2.001e+03,  2.251e-02],\n",
              "       [ 2.002e+03,  2.254e-02],\n",
              "       [ 2.003e+03,  2.132e-02],\n",
              "       [ 2.004e+03,  1.773e-02],\n",
              "       [ 2.005e+03,  1.311e-02],\n",
              "       [ 2.006e+03,  8.010e-03],\n",
              "       [ 2.007e+03,  3.850e-03],\n",
              "       [ 2.008e+03,  1.310e-03],\n",
              "       [ 2.009e+03,  9.900e-04],\n",
              "       [ 2.010e+03,  2.130e-03],\n",
              "       [ 2.011e+03,  3.780e-03],\n",
              "       [ 2.012e+03,  5.130e-03],\n",
              "       [ 2.013e+03,  5.950e-03],\n",
              "       [ 2.014e+03,  5.890e-03],\n",
              "       [ 2.015e+03,  5.260e-03],\n",
              "       [ 2.016e+03,  4.610e-03],\n",
              "       [ 2.017e+03,  4.220e-03]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-AP2Fa7v7zW",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "get_population_growth_rate_by_country_year(population_df,'ABW')\n",
        "```\n",
        "> ```\n",
        "array([[ 1.961e+03,  2.263e-02],\n",
        "       [ 1.962e+03,  1.420e-02],\n",
        "       [ 1.963e+03,  8.360e-03],\n",
        "       [ 1.964e+03,  5.940e-03],\n",
        "            ...       ....\n",
        "       [ 2.015e+03,  5.260e-03],\n",
        "       [ 2.016e+03,  4.610e-03],\n",
        "       [ 2.017e+03,  4.220e-03]])\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y9F9tDmv7zX",
        "colab_type": "text"
      },
      "source": [
        "### Question 2: Even-Odd Train-Test Split\n",
        "\n",
        "Now that we have have our data, we need to split this into a set of variables we will be training on, and the set of variables that we will make our predictions on. In this case, we're splitting the values such that the training set consists of growth rates for even years and the test consists of growth rates for odd years. We also need to split our data into the predictive features (denoted `X`) and the response (denoted `y`). \n",
        "\n",
        "Write a function that will take as input a 2-d numpy array and return four variables in the form of `(X_train, y_train), (X_test, y_test)`, where `(X_train, y_train)` are the features / response of the training set, and `(X-test, y_test)` are the feautes / response of the testing set where the training and testing data consists of even and odd years respectively: \n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should take a 2-d numpy `array` as input.\n",
        "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`.\n",
        "* `(X_train, y_train)` should consist of data from even years and `(X_test, y_test)` should consist of data from odd years."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WplqqmMv7zY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### START FUNCTION\n",
        "def feature_response_split(arr):\n",
        "    # your code here\n",
        "    arr1 = []\n",
        "    arr2 = []\n",
        "    for i in arr:\n",
        "        if i[0]%2!=0:\n",
        "            arr1.append(i)\n",
        "        else:\n",
        "            arr2.append(i) \n",
        "    a = np.array(arr1)\n",
        "    b = np.array(arr2)\n",
        "    X_test = a[:,:1]\n",
        "    y_test= a[:,1:]\n",
        "    X_train = b[:,:1]\n",
        "    y_train= b[:,1:]\n",
        "    return(X_train.ravel(),y_train.ravel()),(X_test.ravel(),y_test.ravel())\n",
        "\n",
        "### END FUNCTION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "a8My2N4Dv7ze",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "4ad4ef92-0cb6-4dd7-bd56-b52c9ab5ba5f"
      },
      "source": [
        "data = get_population_growth_rate_by_country_year(population_df,'ABW');\n",
        "(X_train, y_train), (X_test, y_test) = feature_response_split(data)\n",
        "feature_response_split(data)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([1962., 1964., 1966., 1968., 1970., 1972., 1974., 1976., 1978.,\n",
              "         1980., 1982., 1984., 1986., 1988., 1990., 1992., 1994., 1996.,\n",
              "         1998., 2000., 2002., 2004., 2006., 2008., 2010., 2012., 2014.,\n",
              "         2016.]),\n",
              "  array([ 0.0142 ,  0.00594,  0.00619,  0.0057 ,  0.00574,  0.00673,\n",
              "          0.00473, -0.00117, -0.00436,  0.00193,  0.01285,  0.01021,\n",
              "         -0.00606, -0.01219,  0.0183 ,  0.05591,  0.05787,  0.0358 ,\n",
              "          0.02137,  0.02076,  0.02254,  0.01773,  0.00801,  0.00131,\n",
              "          0.00213,  0.00513,  0.00589,  0.00461])),\n",
              " (array([1961., 1963., 1965., 1967., 1969., 1971., 1973., 1975., 1977.,\n",
              "         1979., 1981., 1983., 1985., 1987., 1989., 1991., 1993., 1995.,\n",
              "         1997., 1999., 2001., 2003., 2005., 2007., 2009., 2011., 2013.,\n",
              "         2015., 2017.]),\n",
              "  array([ 0.02263,  0.00836,  0.00575,  0.00589,  0.00582,  0.00638,\n",
              "          0.00673,  0.00213, -0.00363, -0.00205,  0.00784,  0.01395,\n",
              "          0.00302, -0.01295, -0.00077,  0.03979,  0.06256,  0.04725,\n",
              "          0.02706,  0.0198 ,  0.02251,  0.02132,  0.01311,  0.00385,\n",
              "          0.00099,  0.00378,  0.00595,  0.00526,  0.00422])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y3WRzUav7zj",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "data = get_population_growth_rate_by_country_year(population_df,'ABW')\n",
        "feature_response_split(data)\n",
        "```\n",
        "> ```\n",
        "X_train == array([1962., 1964., 1966., 1968., 1970., 1972., 1974., 1976., 1978.,\n",
        "       1980., 1982., 1984., 1986., 1988., 1990., 1992., 1994., 1996.,\n",
        "       1998., 2000., 2002., 2004., 2006., 2008., 2010., 2012., 2014.,\n",
        "       2016.])\n",
        "```\n",
        "\n",
        "> ```\n",
        "y_train ==  array([ 0.01419604,  0.00594409,  0.00618898,  0.00570149,  0.00573851,\n",
        "        0.00672948,  0.00473084, -0.00117052, -0.00435676,  0.00193398,\n",
        "        0.01284528,  0.01020884, -0.00606099, -0.01219414,  0.01830187,\n",
        "        0.05590975,  0.05787267,  0.03580499,  0.02136897,  0.02076288,\n",
        "        0.02254085,  0.01772885,  0.00800752,  0.00131397,  0.00212906,\n",
        "        0.00513459,  0.00589222,  0.00460988])\n",
        "```\n",
        "\n",
        "> ```\n",
        "X_test == array([1961., 1963., 1965., 1967., 1969., 1971., 1973., 1975., 1977.,\n",
        "       1979., 1981., 1983., 1985., 1987., 1989., 1991., 1993., 1995.,\n",
        "       1997., 1999., 2001., 2003., 2005., 2007., 2009., 2011., 2013.,\n",
        "       2015., 2017.])\n",
        "```\n",
        "\n",
        "> ```\n",
        "y_test == array([ 0.02263378,  0.00835927,  0.00575116,  0.00589102,  0.00582331,\n",
        "        0.00638301,  0.00673463,  0.00213125, -0.0036312 , -0.00204649,\n",
        "        0.00783746,  0.01395387,  0.00302374, -0.01294617, -0.0007695 ,\n",
        "        0.03979147,  0.0625632 ,  0.04724902,  0.02705529,  0.01979903,\n",
        "        0.02250889,  0.02131758,  0.01310552,  0.00384798,  0.00098665,\n",
        "        0.00377696,  0.00594675,  0.00526037,  0.00421667])      \n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go2EEu9Av7zk",
        "colab_type": "text"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "Now that we have formatted our data, we can fit a model using sklearn's `DecisionTreeRegressor` class. We'll write a function that will take as input the features and response variables that we created in the last question, and return a trained model.\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should take two numpy `arrays` as input in the form `(X_train, y_train)` as well as a `MaxDepth` int corresponding to the max_depth hyperparameter in decision trees.\n",
        "* Should return an sklearn `DecisionTreeRegressor` model.\n",
        "* The returned model should be fitted to the data.\n",
        "\n",
        "_**Hint:**_\n",
        "You may need to reshape the data within the function. You can use `.reshape(-1, 1)` to do this.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LY1V-TXv7zk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### START FUNCTION\n",
        "def train_model(X_train, y_train, MaxDepth):\n",
        "    # your code here\n",
        "    lin_m = DecisionTreeRegressor(max_depth=MaxDepth,random_state=42)\n",
        "    lin_m.fit(X_train.reshape(-1,1),y_train)\n",
        "    return lin_m\n",
        "\n",
        "### END FUNCTION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YanS5faUv7zn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6d8cf1a-b9ee-44a6-aee6-6e401571f856"
      },
      "source": [
        "data = get_population_growth_rate_by_country_year(population_df,'ABW')\n",
        "(X_train, y_train), _ = feature_response_split(data)\n",
        "\n",
        "train_model(X_train, y_train,3).predict([[2017]])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00451333])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42asefk3v7zq",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "train_model(X_train, y_train,3).predict([[2017]]) == array([0.00451454])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9hkPoN1v7zr",
        "colab_type": "text"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "We would now like to test on our testing data that we produced from Question 2. This test will give the Root Mean Squared Logarithmic Error (RMSLE), which is given by:\n",
        "\n",
        "$$\n",
        "RMSLE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N [log(1+p_i) - log(1+y_i)]^2}\n",
        "$$\n",
        "\n",
        "where $p_i$ refers to the $i^{\\rm th}$ prediction made from `X_test`, $y_i$ refers to the $i^{\\rm th}$ value in `y_test`, and $N$ is the length of `y_test`.\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should take a trained model and two `arrays` as input. This will be the `X_test` and `y_test` variables from Question 2. \n",
        "* Should return the residual sum of squares over the input from the predicted values of `X_test` as compared to values of `y_test`.\n",
        "* The output should be a `float` rounded to 3 decimal places.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gQoKCHKv7zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### START FUNCTION\n",
        "def test_model(model, y_test, X_test):\n",
        "    # your code here\n",
        "    model_t=[]\n",
        "    for i in range(len(y_test)):\n",
        "        model_t.append((np.log(1+float(model.predict(X_test[i].reshape(-1,1))))-np.log(1+float(y_test[i])))**2)\n",
        "    \n",
        "    return round((sum(model_t)/len(y_test))**0.5,3)\n",
        "\n",
        "### END FUNCTION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEXxzLBIv7zz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e05b284-15a4-475b-b45f-3fbd00756540"
      },
      "source": [
        "data = get_population_growth_rate_by_country_year(population_df,'ABW')\n",
        "(X_train, y_train), (X_test, y_test) = feature_response_split(data)\n",
        "lm = train_model(X_train, y_train,3)\n",
        "test_model(lm, y_test, X_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.008"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0id1L9lZv7z2",
        "colab_type": "text"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "test_model(lm, X_test, y_test) == 0.008\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5ngvwusv7z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}